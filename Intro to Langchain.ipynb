{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Langchain ?\n",
    "#### An open source framework that allows  developers to combine LLMs like GPT-4 with external sources of computation and data.\n",
    "\n",
    "#### Langchain Framework is offered as Python and TypeScript Package\n",
    "\n",
    "### Why we need Langchain ?\n",
    "\n",
    "we're going to see why the popularity of the framework is exploding right now especially after the introduction of\n",
    "gpt4 in March 2023 to understand what\n",
    "need Lang chain fills let's have a look\n",
    "at a practical example so by now we all\n",
    "know that chat typically or tpt4 has an\n",
    "impressive general knowledge we can ask\n",
    "it about almost anything and we'll get a\n",
    "pretty good answer\n",
    "suppose you want to know something\n",
    "specifically from your own data your own\n",
    "document it could be a book a PDF file a\n",
    "database with proprietary information\n",
    "link chain allows you to connect a large\n",
    "language model like GPT-4 to your own\n",
    "sources of data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages (0.1.6)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.18 in /opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages (from langchain) (0.0.19)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.22 in /opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages (from langchain) (0.1.22)\n",
      "Requirement already satisfied: langsmith<0.1,>=0.0.83 in /opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages (from langchain) (0.0.87)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages (from langchain) (2.6.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: anyio<5,>=3 in /opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.22->langchain) (4.2.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.22->langchain) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.16.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.22->langchain) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.22->langchain) (1.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we are going to start with LLM Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Large language models are advanced artificial intelligence systems that have been trained on massive amounts of data to generate human-like text responses.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "llm(\"explain large language models in one sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import(\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\",temperature=0.3)\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are an expert data scientist\"),\n",
    "    HumanMessage(content=\"Write a python script that trains a neural network on simulated data\")\n",
    "]\n",
    "response = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here's an example of a Python script that trains a neural network on simulated data using the Keras library:\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "from keras.models import Sequential\n",
      "from keras.layers import Dense\n",
      "\n",
      "# Generate simulated data\n",
      "np.random.seed(0)\n",
      "X = np.random.rand(100, 2)\n",
      "y = np.random.randint(2, size=100)\n",
      "\n",
      "# Define the model architecture\n",
      "model = Sequential()\n",
      "model.add(Dense(10, input_dim=2, activation='relu'))\n",
      "model.add(Dense(1, activation='sigmoid'))\n",
      "\n",
      "# Compile the model\n",
      "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
      "\n",
      "# Train the model\n",
      "model.fit(X, y, epochs=100, batch_size=10)\n",
      "\n",
      "# Evaluate the model\n",
      "loss, accuracy = model.evaluate(X, y)\n",
      "print(f\"Loss: {loss}\")\n",
      "print(f\"Accuracy: {accuracy}\")\n",
      "```\n",
      "\n",
      "In this script, we first generate simulated data using `np.random.rand()` and `np.random.randint()`. We then define a neural network model using the `Sequential` class from Keras. The model consists of two dense layers with 10 and 1 neurons, respectively. The first layer uses the ReLU activation function, and the second layer uses the sigmoid activation function.\n",
      "\n",
      "After defining the model, we compile it using the binary cross-entropy loss function and the Adam optimizer. We then train the model using the `fit()` method, specifying the number of epochs and the batch size.\n",
      "\n",
      "Finally, we evaluate the trained model on the same data and print the loss and accuracy.\n"
     ]
    }
   ],
   "source": [
    "print(response.content,end=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept 2 : Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "You are an expert data scientist with expertise in building deep learning models.\n",
    "Explain the concept of {concept} in couple of lines\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"concept\"],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['concept'], template='\\nYou are an expert data scientist with expertise in building deep learning models.\\nExplain the concept of {concept} in couple of lines\\n')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Backpropagation is a key algorithm used in training deep learning models. It involves propagating the error from the output layer back to the input layer, adjusting the weights and biases of each neuron in the network based on the calculated error. This iterative process enables the network to learn and improve its predictions by minimizing the difference between predicted and actual outputs.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(prompt.format(concept=\"backpropagation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_community.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-9S6BvFHlZO0c19LM2TkWffly on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain_community.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-9S6BvFHlZO0c19LM2TkWffly on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Autoencoders are neural networks that are trained to learn efficient representations of input data by attempting to reconstruct the input themselves. They consist of an encoder that compresses the input data into a lower-dimensional representation, and a decoder that tries to reconstruct the original input from this representation. The hidden layer in the middle provides a condensed representation of the input, allowing autoencoders to be used for tasks like dimensionality reduction, anomaly detection, and generative modeling.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(prompt.format(concept=\"autoencoders\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept 3: Chains\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "Retrying langchain_community.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-9S6BvFHlZO0c19LM2TkWffly on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain_community.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-9S6BvFHlZO0c19LM2TkWffly on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain_community.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-9S6BvFHlZO0c19LM2TkWffly on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoders are neural networks that are trained to reconstruct their input data. They consist of an encoder that compresses the data into a lower-dimensional representation and a decoder that reconstructs the original data from this representation. By doing so, autoencoders can learn powerful feature representations and are often used for data compression, dimensionality reduction, and anomaly detection.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Run the chain only specifying the input variables\n",
    "print(chain.run(\"autoencoders\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building a sequential chain\n",
    "\n",
    "second_prompt = PromptTemplate(\n",
    "    input_variables=[\"ml_concept\"],\n",
    "    template=\"Turn the concept description of {ml_concept} and explain it to me like I am a 5 year old in 500 words\",\n",
    ")\n",
    "\n",
    "second_chain = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_community.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-9S6BvFHlZO0c19LM2TkWffly on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_community.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-9S6BvFHlZO0c19LM2TkWffly on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain_community.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-9S6BvFHlZO0c19LM2TkWffly on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain_community.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-9S6BvFHlZO0c19LM2TkWffly on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain_community.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-9S6BvFHlZO0c19LM2TkWffly on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3mAutoencoders are neural network models that aim to learn a representation of the input data by compressing it into a lower-dimensional code and then reconstructing it back to the original form. They consist of an encoder that compresses the data and a decoder that reconstructs it, and are often used for dimensionality reduction, anomaly detection, and data generation tasks.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_community.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-9S6BvFHlZO0c19LM2TkWffly on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain_community.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-9S6BvFHlZO0c19LM2TkWffly on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m\u001b[1;3mAutoencoders are like special \"thinking\" machines that can learn and understand things just like our brain! They can look at and understand all sorts of pictures, sounds, and other cool stuff.\n",
      "\n",
      "Imagine you have toy building blocks of different colors, shapes, and sizes. Autoencoders are like magic boxes that can take these blocks and squish them down into a smaller box, sort of like when you squash your playdough to make it smaller.\n",
      "\n",
      "But, the magic doesn't stop there! These squished blocks can be taken out of the smaller box and put back together by the autoencoder. It's like when you take your squished playdough, un-squish it, and get your original shapes back!\n",
      "\n",
      "So why do we need these magic boxes? Well, sometimes we have too many building blocks and they get too complicated. When that happens, the autoencoder can help us make sense of it all by squishing everything down into a simpler form. It's like making a big puzzle easier to solve by turning it into a smaller puzzle.\n",
      "\n",
      "Autoencoders are really good at helping us understand and solve problems. For example, they can help us find things that are strange or different from everything else. It's like having a superpower that can spot something weird in a huge crowd of people.\n",
      "\n",
      "They're also really good at making things up! Like when you use your imagination to draw something that doesn't exist, the autoencoder can imagine new pictures or sounds. It's like having a magical artist or musician that creates things nobody has ever seen or heard before.\n",
      "\n",
      "So, to sum it up, autoencoders are like magical \"thinking\" machines that can learn and understand all sorts of things, just like our brain. They can squish complicated things into simpler forms, help us find strange things, and even create new things that are unique and special.\n",
      "\n",
      "And the best part is, all of this happens inside these special neural network models called autoencoders. They're like special computers that work just like our brain to understand and do amazing things with lots of different information.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Autoencoders are like special \"thinking\" machines that can learn and understand things just like our brain! They can look at and understand all sorts of pictures, sounds, and other cool stuff.\n",
      "\n",
      "Imagine you have toy building blocks of different colors, shapes, and sizes. Autoencoders are like magic boxes that can take these blocks and squish them down into a smaller box, sort of like when you squash your playdough to make it smaller.\n",
      "\n",
      "But, the magic doesn't stop there! These squished blocks can be taken out of the smaller box and put back together by the autoencoder. It's like when you take your squished playdough, un-squish it, and get your original shapes back!\n",
      "\n",
      "So why do we need these magic boxes? Well, sometimes we have too many building blocks and they get too complicated. When that happens, the autoencoder can help us make sense of it all by squishing everything down into a simpler form. It's like making a big puzzle easier to solve by turning it into a smaller puzzle.\n",
      "\n",
      "Autoencoders are really good at helping us understand and solve problems. For example, they can help us find things that are strange or different from everything else. It's like having a superpower that can spot something weird in a huge crowd of people.\n",
      "\n",
      "They're also really good at making things up! Like when you use your imagination to draw something that doesn't exist, the autoencoder can imagine new pictures or sounds. It's like having a magical artist or musician that creates things nobody has ever seen or heard before.\n",
      "\n",
      "So, to sum it up, autoencoders are like magical \"thinking\" machines that can learn and understand all sorts of things, just like our brain. They can squish complicated things into simpler forms, help us find strange things, and even create new things that are unique and special.\n",
      "\n",
      "And the best part is, all of this happens inside these special neural network models called autoencoders. They're like special computers that work just like our brain to understand and do amazing things with lots of different information.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "overall_chain = SimpleSequentialChain(chains=[chain, second_chain], verbose=True)\n",
    "\n",
    "# Run the chain specifying only the input variables for the first chain.Config\n",
    "explaination = overall_chain.run(\"autoencoders\")\n",
    "print(explaination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's split the text into chunks to store it into a pinecone "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "\n",
    "texts = text_splitter.create_documents([explaination])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Autoencoders are like special \"thinking\" machines that can learn and understand things just like our'),\n",
       " Document(page_content='brain! They can look at and understand all sorts of pictures, sounds, and other cool stuff.'),\n",
       " Document(page_content='Imagine you have toy building blocks of different colors, shapes, and sizes. Autoencoders are like'),\n",
       " Document(page_content='magic boxes that can take these blocks and squish them down into a smaller box, sort of like when'),\n",
       " Document(page_content='you squash your playdough to make it smaller.'),\n",
       " Document(page_content=\"But, the magic doesn't stop there! These squished blocks can be taken out of the smaller box and\"),\n",
       " Document(page_content=\"put back together by the autoencoder. It's like when you take your squished playdough, un-squish\"),\n",
       " Document(page_content='it, and get your original shapes back!'),\n",
       " Document(page_content='So why do we need these magic boxes? Well, sometimes we have too many building blocks and they get'),\n",
       " Document(page_content='too complicated. When that happens, the autoencoder can help us make sense of it all by squishing'),\n",
       " Document(page_content=\"everything down into a simpler form. It's like making a big puzzle easier to solve by turning it\"),\n",
       " Document(page_content='into a smaller puzzle.'),\n",
       " Document(page_content='Autoencoders are really good at helping us understand and solve problems. For example, they can'),\n",
       " Document(page_content=\"help us find things that are strange or different from everything else. It's like having a\"),\n",
       " Document(page_content='superpower that can spot something weird in a huge crowd of people.'),\n",
       " Document(page_content=\"They're also really good at making things up! Like when you use your imagination to draw something\"),\n",
       " Document(page_content=\"that doesn't exist, the autoencoder can imagine new pictures or sounds. It's like having a magical\"),\n",
       " Document(page_content='artist or musician that creates things nobody has ever seen or heard before.'),\n",
       " Document(page_content='So, to sum it up, autoencoders are like magical \"thinking\" machines that can learn and understand'),\n",
       " Document(page_content='all sorts of things, just like our brain. They can squish complicated things into simpler forms,'),\n",
       " Document(page_content='help us find strange things, and even create new things that are unique and special.'),\n",
       " Document(page_content='And the best part is, all of this happens inside these special neural network models called'),\n",
       " Document(page_content=\"autoencoders. They're like special computers that work just like our brain to understand and do\"),\n",
       " Document(page_content='amazing things with lots of different information.')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Autoencoders are like special \"thinking\" machines that can learn and understand things just like our'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#splitting the texts\n",
    "# extract plain text of page content\n",
    "texts[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# turn this into embedding .. Let's Use OpenAI Model\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings(model_name=\"ada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.03119055238105698,\n",
       " -0.004886030481666134,\n",
       " 0.0006766235174074547,\n",
       " -0.01731622519497153,\n",
       " -0.008304584425530406,\n",
       " 0.014728130159321565,\n",
       " -0.0034002103823679644,\n",
       " -0.02772197011887435,\n",
       " -0.0035152738846857498,\n",
       " -0.027935421793505912,\n",
       " 0.00630014456647137,\n",
       " 0.0454384181351026,\n",
       " -0.00014820681209434382,\n",
       " -0.009878786800648048,\n",
       " -0.018636954172125457,\n",
       " 0.012413519848962658,\n",
       " 0.002049464647053656,\n",
       " 0.018343459050829593,\n",
       " -0.011866550398380542,\n",
       " -0.010599184339884505,\n",
       " -0.014127798721404095,\n",
       " 0.015621957649857436,\n",
       " 0.015408505975225872,\n",
       " -0.02315945081817256,\n",
       " -0.0018960467215734871,\n",
       " -0.015408505975225872,\n",
       " 0.008144495669556733,\n",
       " -0.03874138581337531,\n",
       " -0.0190238348667339,\n",
       " -0.0022328993306942055,\n",
       " 0.013420742377493378,\n",
       " -0.01310723592887017,\n",
       " -0.021731997866347923,\n",
       " -0.02780201542818372,\n",
       " -0.03252462162221411,\n",
       " -0.01991766235726977,\n",
       " -0.0020394592162206186,\n",
       " -0.0062267707861474045,\n",
       " 0.013087224601542826,\n",
       " -0.0020261184865561456,\n",
       " 0.009378511068044758,\n",
       " 0.020477972071855092,\n",
       " 0.0012748704226591074,\n",
       " -0.01594213329915971,\n",
       " -0.009265115098727373,\n",
       " 0.010745931900532439,\n",
       " -0.02838900567077545,\n",
       " -0.023573013903432485,\n",
       " -0.016409059303077525,\n",
       " 0.00031183882831131964,\n",
       " 0.017276204402961914,\n",
       " 0.016075541527126973,\n",
       " -0.01035238200524493,\n",
       " 0.0008300415593029404,\n",
       " -0.034338957131292265,\n",
       " 0.02557411869649072,\n",
       " -0.03420555076597007,\n",
       " 0.008231210179545171,\n",
       " 0.0411693920930516,\n",
       " -0.007837660284257664,\n",
       " -0.01240684878563852,\n",
       " 0.0006707869772830771,\n",
       " -0.03180422501430019,\n",
       " 0.015581934995202749,\n",
       " -0.00326513578555347,\n",
       " 0.00478931077367529,\n",
       " -0.0020961572008793105,\n",
       " -0.002504716057323595,\n",
       " 0.011386285993104595,\n",
       " 0.002461358802329375,\n",
       " 0.04058240185045987,\n",
       " -0.010805964951191932,\n",
       " -0.025440710468523454,\n",
       " -0.0003689536671162828,\n",
       " 0.015568594731199545,\n",
       " -0.013540808478812364,\n",
       " 0.004765964380347146,\n",
       " -0.028709181320077725,\n",
       " -0.006256787311477151,\n",
       " 0.020824830111808846,\n",
       " 0.02466695094195164,\n",
       " -0.02822891691480178,\n",
       " -0.03297820549948365,\n",
       " 0.016409059303077525,\n",
       " 0.012213409369656834,\n",
       " -0.012807069744250166,\n",
       " 0.005763181710875463,\n",
       " 0.019570804317316014,\n",
       " 0.00929846669005792,\n",
       " 0.005126163149965375,\n",
       " 0.011993287563023668,\n",
       " -0.002306273111018172,\n",
       " 0.02646794432438152,\n",
       " -0.004769299446347948,\n",
       " -0.011593066604412021,\n",
       " 0.009411862659375306,\n",
       " 0.0022128882361974966,\n",
       " 0.014181161640061985,\n",
       " -0.008744827107474203,\n",
       " -0.01907719778539179,\n",
       " -0.0004590033886246692,\n",
       " 0.03140400219304347,\n",
       " -0.016489102749741826,\n",
       " -0.015648638177863845,\n",
       " -0.0077709566359353,\n",
       " 0.00924510377140003,\n",
       " 0.011126142463139277,\n",
       " 0.001226510452248369,\n",
       " 0.012026639154354216,\n",
       " 0.008791519894130493,\n",
       " 0.008511365036837831,\n",
       " 0.03385869272601632,\n",
       " -0.0014366263623872301,\n",
       " -0.02652130724303941,\n",
       " 0.017142796174994653,\n",
       " -0.008071122354894034,\n",
       " -0.008017759436236144,\n",
       " 0.0136208528567992,\n",
       " 0.006356842551130062,\n",
       " 0.007777626767936902,\n",
       " 0.013594171397470255,\n",
       " 0.03684700872027793,\n",
       " 0.026054383101766665,\n",
       " -0.007103921549695465,\n",
       " 0.02119836867976901,\n",
       " 0.006056676832171327,\n",
       " -1.7913535366194103e-06,\n",
       " 0.005793198236205209,\n",
       " 0.006983855448376478,\n",
       " -0.004559183303378452,\n",
       " -0.0029249481104319506,\n",
       " -0.003591982963841151,\n",
       " 0.014608064058002577,\n",
       " 0.03572638929110729,\n",
       " -0.016635851241712293,\n",
       " 0.023399584883455605,\n",
       " 0.011693121378403665,\n",
       " 0.014101118193397684,\n",
       " 0.007344054217994707,\n",
       " -0.029189447587998747,\n",
       " 0.007610868345622895,\n",
       " -0.009058333556097411,\n",
       " -0.02425338971933679,\n",
       " 0.004672579272695837,\n",
       " -0.010439096515233368,\n",
       " -0.003368526324037817,\n",
       " -0.0015558589300366508,\n",
       " 0.03740731843486325,\n",
       " -0.003291817244882416,\n",
       " 0.022118876698311293,\n",
       " 0.01157972540908628,\n",
       " -0.0326580279875363,\n",
       " 0.005022772844311662,\n",
       " -0.004198984533760224,\n",
       " 0.03922165021865126,\n",
       " 0.0189437914200696,\n",
       " -0.011206185909803578,\n",
       " 0.015381824515896926,\n",
       " -0.032924840718180685,\n",
       " 0.005679802266887825,\n",
       " 0.012793729480246962,\n",
       " 0.008404640130844587,\n",
       " -0.013207290702861814,\n",
       " -0.0043624083557346986,\n",
       " 0.030790331422445333,\n",
       " 0.01706275272833035,\n",
       " 0.00863143113815682,\n",
       " 0.01498160355728528,\n",
       " 0.008584739282823066,\n",
       " -0.012927136776891689,\n",
       " -0.019984365539930864,\n",
       " -0.006566958694099558,\n",
       " -0.007264009840007871,\n",
       " 0.025080512164566495,\n",
       " 0.002012777756891673,\n",
       " 0.014287887477377767,\n",
       " -0.01111947139981514,\n",
       " -0.011332923074446704,\n",
       " -0.027535200834894268,\n",
       " -0.002424671912167392,\n",
       " -0.0034652462648592937,\n",
       " 0.020918213822476352,\n",
       " 0.0355929829257851,\n",
       " -0.0006903811303220276,\n",
       " -0.02145184300905526,\n",
       " -0.011379614929780457,\n",
       " 0.023452947802113495,\n",
       " -0.01411445845740089,\n",
       " 0.009858775473320706,\n",
       " -0.018530230197454745,\n",
       " -0.003985533324789928,\n",
       " 0.018089986584188412,\n",
       " 0.008891575599444672,\n",
       " 0.0031734184437331955,\n",
       " -0.6403534741739928,\n",
       " -0.0005052789136810775,\n",
       " 0.02710829748563114,\n",
       " -0.01422118429471667,\n",
       " 0.01011224887128442,\n",
       " 0.016208947892449165,\n",
       " 0.004442452268060267,\n",
       " -0.017182818829649338,\n",
       " -0.022479076864913326,\n",
       " 0.009098356210752098,\n",
       " -0.002246240060358678,\n",
       " 0.011252878696459868,\n",
       " -0.007190636059683905,\n",
       " -0.006206759924481329,\n",
       " 0.008071122354894034,\n",
       " -0.003150072283235685,\n",
       " 0.0004748454759974014,\n",
       " -0.012133364991669999,\n",
       " 0.011853210134377339,\n",
       " -0.0007108090498611784,\n",
       " -0.014141139916729835,\n",
       " 0.01278705934824536,\n",
       " -0.03223112463827318,\n",
       " -0.01388766651876612,\n",
       " -0.0028715851917740596,\n",
       " 0.01001886422929438,\n",
       " 0.009938819851307542,\n",
       " -0.03156409281166222,\n",
       " -0.002144517287705366,\n",
       " 0.01127289002378721,\n",
       " -0.047519566374825135,\n",
       " 0.02761524428155857,\n",
       " 0.004472468793390014,\n",
       " -0.013780940681450339,\n",
       " 0.052802482283440845,\n",
       " 0.0034619111988584924,\n",
       " -0.01706275272833035,\n",
       " 0.03676696341096856,\n",
       " 0.0073107026266641595,\n",
       " 0.04703930196954918,\n",
       " -0.023146110554169354,\n",
       " -0.020904873558473147,\n",
       " 0.04119607634634816,\n",
       " -0.002668139646467435,\n",
       " 0.01854357046145795,\n",
       " 0.03916828916263844,\n",
       " -0.017756468808237863,\n",
       " 0.02315945081817256,\n",
       " -0.009545269024697498,\n",
       " -0.02932285395332094,\n",
       " 0.006446892127119303,\n",
       " -0.004752623650682674,\n",
       " -0.0052895869719398496,\n",
       " 0.0061433913421597664,\n",
       " -0.001304887064404171,\n",
       " 0.020971576741134243,\n",
       " 0.033325063539437406,\n",
       " -0.01999770580393407,\n",
       " 0.0411693920930516,\n",
       " -0.007264009840007871,\n",
       " 0.033245018230128036,\n",
       " 0.006490249382113522,\n",
       " -0.009992182769965432,\n",
       " -0.016288991339113466,\n",
       " -0.01632901399376815,\n",
       " 0.01107944967648299,\n",
       " -0.00404223130944862,\n",
       " 0.001282374553991544,\n",
       " -0.03052351682915588,\n",
       " -0.006263457909140021,\n",
       " 0.053949782240617895,\n",
       " 0.024987126591253916,\n",
       " -0.013794281876776079,\n",
       " -0.007744275176606354,\n",
       " -0.007183965927682302,\n",
       " 0.02114500576111112,\n",
       " 0.012006627827026873,\n",
       " -0.004575859564704994,\n",
       " -0.026361218487065737,\n",
       " 0.006090028423501875,\n",
       " 0.016022178608469082,\n",
       " -0.0056464502098960085,\n",
       " -0.01971755094664141,\n",
       " -0.01961082510932563,\n",
       " 0.020464629945206814,\n",
       " -0.02183872184101863,\n",
       " -0.0005582248326735514,\n",
       " -0.013367379458835487,\n",
       " -0.012820410939575907,\n",
       " 0.027908739402854432,\n",
       " 0.0030049922555881532,\n",
       " 0.013067213274215483,\n",
       " -0.0227992525142156,\n",
       " -0.04127611793036738,\n",
       " 0.004002209586116469,\n",
       " -0.014701448699992618,\n",
       " -0.020984917005137448,\n",
       " -0.003988868856451997,\n",
       " 0.016435739831083936,\n",
       " 0.002359636029676063,\n",
       " 0.013700897234786038,\n",
       " -0.02932285395332094,\n",
       " 0.005763181710875463,\n",
       " 0.016689212297725114,\n",
       " -0.004715936527690056,\n",
       " 0.009925479587304336,\n",
       " 0.002312943475850408,\n",
       " 0.003418553943864273,\n",
       " 0.04052904079444705,\n",
       " -0.03006993295188634,\n",
       " -0.0003687452254912327,\n",
       " -0.011726473901056748,\n",
       " 0.014874878651292034,\n",
       " 0.029269491034663045,\n",
       " -0.01647576248573862,\n",
       " -0.025053831636560085,\n",
       " 0.005673131669224955,\n",
       " 0.03383200847271976,\n",
       " -0.0026631368146355994,\n",
       " -0.029803118358596885,\n",
       " 0.02897599591336718,\n",
       " 0.0043624083557346986,\n",
       " -0.010045545688623325,\n",
       " -0.0030133301534207902,\n",
       " 0.004619216819699214,\n",
       " 0.0372472278162445,\n",
       " -0.014421294774022495,\n",
       " -0.023879849288731554,\n",
       " -0.018863746110760225,\n",
       " 0.0009580288498274397,\n",
       " 0.010585844075881302,\n",
       " -0.017969920482869425,\n",
       " -0.008031100631561884,\n",
       " -0.013314016540177595,\n",
       " 0.007270680437670741,\n",
       " 0.003451905535194821,\n",
       " 0.03516607957652197,\n",
       " -0.017556359260254575,\n",
       " 0.010685898849872946,\n",
       " 0.007730934446941881,\n",
       " -0.03348515043276601,\n",
       " -0.007897693334917157,\n",
       " 0.010565832748553957,\n",
       " 0.01166643991907472,\n",
       " -0.029616349074616802,\n",
       " -0.015995496217817602,\n",
       " 0.008931597322776822,\n",
       " 0.00037812541876060783,\n",
       " -0.01731622519497153,\n",
       " 0.010525811025221807,\n",
       " -0.01471478989531836,\n",
       " -0.010225644840601804,\n",
       " -0.016969367155017772,\n",
       " 0.022465734738265047,\n",
       " 0.019063857521388585,\n",
       " -0.028602457345407017,\n",
       " -0.007197306657346775,\n",
       " -0.016102222055133383,\n",
       " -0.03391205378202913,\n",
       " -0.016595828587057607,\n",
       " -0.009271785230728975,\n",
       " 0.002312943475850408,\n",
       " -0.015288439873906885,\n",
       " -0.00025097189473630887,\n",
       " -0.00647690865244905,\n",
       " 0.012026639154354216,\n",
       " -0.009965501310636487,\n",
       " 0.020531334990512982,\n",
       " -0.014834855996637347,\n",
       " -0.010699240045198686,\n",
       " 0.03065692319447807,\n",
       " -0.018476867278796855,\n",
       " 0.010005523033968637,\n",
       " 0.014314568936706714,\n",
       " -0.008991630373436315,\n",
       " 0.00015039552191694271,\n",
       " -0.0001310098250549569,\n",
       " -0.010719250441203493,\n",
       " 0.019957685011924457,\n",
       " -0.010385733596575478,\n",
       " 0.007670901396282388,\n",
       " -0.010512469829896067,\n",
       " -0.008044440895565089,\n",
       " 0.005226218389618287,\n",
       " -0.002623114625642181,\n",
       " 0.009445214250705854,\n",
       " 0.011112801267813537,\n",
       " 0.009885456932649651,\n",
       " -0.01631567372976495,\n",
       " -0.01531512133323583,\n",
       " 0.0075775162886310785,\n",
       " 0.0250138089819054,\n",
       " -0.009238433639398427,\n",
       " 0.030336747545175794,\n",
       " 0.021318434781087997,\n",
       " 0.009258444035403235,\n",
       " -0.00036520160145006445,\n",
       " 0.009431873055380112,\n",
       " -0.009898798127975391,\n",
       " 0.015395165711222666,\n",
       " -0.026147768675079244,\n",
       " -0.01913056070404968,\n",
       " 0.01051913996189767,\n",
       " 0.002866582359942224,\n",
       " 0.023012704188847162,\n",
       " -0.03780753753082983,\n",
       " 0.020971576741134243,\n",
       " -0.009371840004720619,\n",
       " 0.0265746701616973,\n",
       " 0.008598079546826272,\n",
       " -0.03289816019017428,\n",
       " -0.0205846960465258,\n",
       " -0.009692017516667966,\n",
       " -0.010192293249271256,\n",
       " 0.0073107026266641595,\n",
       " 0.027508518444242784,\n",
       " 0.0024296745111685937,\n",
       " 0.02721502332294692,\n",
       " -0.006636997408422722,\n",
       " -0.006053341766170526,\n",
       " 0.01107944967648299,\n",
       " -0.011366274665777252,\n",
       " -0.01246021170429641,\n",
       " 0.002402993284670282,\n",
       " 0.03607324733106104,\n",
       " 0.03940842136527641,\n",
       " -0.004198984533760224,\n",
       " 0.03799430867745498,\n",
       " -0.004105599891770183,\n",
       " -0.02876254423873562,\n",
       " 0.00952525862869269,\n",
       " 0.005432999466586981,\n",
       " 0.005793198236205209,\n",
       " 0.02520057826588548,\n",
       " 0.006176742933490314,\n",
       " 0.011139482727142483,\n",
       " 0.007690912257948463,\n",
       " -0.011673110982398857,\n",
       " 0.021571909110374248,\n",
       " 0.018330118786826388,\n",
       " -0.011012746493821893,\n",
       " 0.018503547806803265,\n",
       " -0.014701448699992618,\n",
       " -0.024573565368639066,\n",
       " 0.012073331941010504,\n",
       " 0.0029416239060972246,\n",
       " 0.02402659778070202,\n",
       " -0.01181985854304679,\n",
       " -0.0242000268006789,\n",
       " 0.020264520397223526,\n",
       " -0.01644908009508714,\n",
       " 0.008564727955495724,\n",
       " -0.002159525550370239,\n",
       " 0.025920976736444473,\n",
       " 0.0074774610489781665,\n",
       " -0.0020878193030466736,\n",
       " 0.013173939111531266,\n",
       " 0.006380188944458207,\n",
       " 0.012326805338974218,\n",
       " 0.021331776907736275,\n",
       " -0.006550282898434284,\n",
       " -0.005052789369641409,\n",
       " -0.002788205980617056,\n",
       " -0.005029442976313264,\n",
       " 0.002791541046617857,\n",
       " -0.00180599702916893,\n",
       " 0.01089267946118037,\n",
       " -0.020411267026548923,\n",
       " -0.01494158183395313,\n",
       " 0.02223894279963028,\n",
       " -0.025667502407158226,\n",
       " -0.0015925458201986337,\n",
       " -0.00472927725735453,\n",
       " -0.008157836864882475,\n",
       " 0.017502996341596685,\n",
       " 0.019223946277362257,\n",
       " 0.024466839531323285,\n",
       " 0.02604104283776346,\n",
       " 0.009905468259976994,\n",
       " 0.029669711993274693,\n",
       " -0.009438544118704251,\n",
       " -0.04805319556140404,\n",
       " 0.022625823494238723,\n",
       " 0.02550741365118455,\n",
       " 0.005709818792217571,\n",
       " -0.018103326848191617,\n",
       " -0.03049683630114947,\n",
       " -0.013994392356081903,\n",
       " -0.0004137700716935113,\n",
       " 0.012873773858233798,\n",
       " -0.026281175040401436,\n",
       " 0.03471249569925243,\n",
       " -0.011599736736413624,\n",
       " 0.007230658248677323,\n",
       " -0.04485142789251087,\n",
       " -0.0052162127259546155,\n",
       " 0.027962102321512323,\n",
       " -0.0027565216894562747,\n",
       " -0.0009004970986685472,\n",
       " 0.008811531221457836,\n",
       " -0.008931597322776822,\n",
       " 0.006103369153166348,\n",
       " -0.014234524558719876,\n",
       " -0.027308408896259496,\n",
       " 0.03898151801601328,\n",
       " 0.027175002530937305,\n",
       " -0.007851000548260868,\n",
       " -0.005436334532587782,\n",
       " -0.002729840230127329,\n",
       " -0.021825381577015426,\n",
       " -0.00556640629757044,\n",
       " 0.002264583389024353,\n",
       " 0.004515826048384233,\n",
       " 0.02003772845858876,\n",
       " 0.00017249106176798186,\n",
       " -0.0014841526827130852,\n",
       " -0.016235630283100648,\n",
       " -0.02030454305187821,\n",
       " 0.011012746493821893,\n",
       " 0.015128351117933212,\n",
       " -0.007951056253575048,\n",
       " -0.0469325761322334,\n",
       " 0.003978863192788325,\n",
       " 0.02139848009039737,\n",
       " 0.04685253082292403,\n",
       " 0.01627565107511026,\n",
       " -0.029856481277254775,\n",
       " -0.0035086035198535134,\n",
       " -0.028602457345407017,\n",
       " 0.001959415071064416,\n",
       " -0.03644678589902121,\n",
       " -0.014301228672703508,\n",
       " 0.02243905421025864,\n",
       " 0.00648357925011192,\n",
       " -0.02282593490486708,\n",
       " 0.0013907678078924097,\n",
       " 0.005453010328253056,\n",
       " -0.021358457435742686,\n",
       " 0.008904915863447877,\n",
       " 0.03340510884874678,\n",
       " 0.0030700281380794826,\n",
       " -0.026361218487065737,\n",
       " -0.02937621687197883,\n",
       " -0.02565416214315502,\n",
       " 6.962176558944906e-05,\n",
       " 0.0033835345867026904,\n",
       " 0.010012194097292777,\n",
       " -0.0002957882993135374,\n",
       " 0.02293265887953779,\n",
       " -0.020958236477131038,\n",
       " 0.0012415187149132424,\n",
       " 0.03006993295188634,\n",
       " -0.014648086712657264,\n",
       " -0.03511271852050915,\n",
       " 0.010699240045198686,\n",
       " 0.036126608387073864,\n",
       " 0.0028732527247744603,\n",
       " -0.008344606148862557,\n",
       " -0.018116667112194822,\n",
       " 0.03407214440064788,\n",
       " 0.015355143056567981,\n",
       " 0.026081063629773076,\n",
       " 0.013507456887481816,\n",
       " 0.000504028263930777,\n",
       " 0.020571355782522595,\n",
       " 0.053843056403302114,\n",
       " 0.021225051070420494,\n",
       " -0.020971576741134243,\n",
       " -0.015848749588492205,\n",
       " 0.0023346221033475178,\n",
       " -0.00145830498988434,\n",
       " 0.002496378159490958,\n",
       " 0.01526175841457794,\n",
       " -0.024520202449981175,\n",
       " 0.021078302578450024,\n",
       " -0.01947741874400344,\n",
       " -0.04357071784472148,\n",
       " 0.0010814303081855203,\n",
       " 0.009692017516667966,\n",
       " 0.00027598567554570756,\n",
       " -0.0009713695794919125,\n",
       " 0.005019437778310861,\n",
       " -0.015822067197840725,\n",
       " 0.008538046496166778,\n",
       " 0.0027448484927922023,\n",
       " 0.008618090874153614,\n",
       " -0.002329619271515682,\n",
       " -0.016795938135040895,\n",
       " 0.004445787799722336,\n",
       " 0.0034652462648592937,\n",
       " -0.0030133301534207902,\n",
       " 0.004976080523316642,\n",
       " -0.019677530154631796,\n",
       " -0.0011014414026822295,\n",
       " -0.009905468259976994,\n",
       " -0.002416334014334755,\n",
       " -0.037674131165507635,\n",
       " -0.002149519886706568,\n",
       " 0.004522496646047103,\n",
       " 0.014901559179298442,\n",
       " 0.008251221506872516,\n",
       " -0.029589668546610392,\n",
       " -0.021518546191716358,\n",
       " 0.03372528263540398,\n",
       " -0.007797638095264245,\n",
       " -0.014528019680015741,\n",
       " 0.02221226227162387,\n",
       " -0.027348431550914185,\n",
       " -0.029909844195912666,\n",
       " 0.0037887581443155393,\n",
       " -0.016969367155017772,\n",
       " -0.020958236477131038,\n",
       " -0.01619560762844596,\n",
       " 0.0009738709372001718,\n",
       " 0.017636402706918877,\n",
       " -0.0219054268863248,\n",
       " 0.027935421793505912,\n",
       " 0.0181300092388431,\n",
       " -0.01700938980967246,\n",
       " 0.016435739831083936,\n",
       " 0.025800910635125487,\n",
       " 0.02718834279494051,\n",
       " 0.007657560666617915,\n",
       " -0.04007545691717752,\n",
       " 0.0029499618039298616,\n",
       " -0.012166716583000546,\n",
       " -0.013100565796868567,\n",
       " -0.02019781721456243,\n",
       " 0.013053873010212278,\n",
       " -0.020291200925229937,\n",
       " 0.0020277860195565462,\n",
       " -0.0011989952264192232,\n",
       " 0.0024830374298264847,\n",
       " -0.023399584883455605,\n",
       " 0.015661980304512123,\n",
       " 0.000758752195229475,\n",
       " 0.025400689676513842,\n",
       " -0.016902663972356676,\n",
       " 0.003782087779483303,\n",
       " -0.005262905512610903,\n",
       " -0.0062601223774779525,\n",
       " -0.013647534316128147,\n",
       " -0.0010789288922696024,\n",
       " -0.003291817244882416,\n",
       " 0.004479139391052884,\n",
       " -0.043090453439445536,\n",
       " 0.0501877048571394,\n",
       " -0.016435739831083936,\n",
       " 0.0004477471625221849,\n",
       " -0.011286230287790416,\n",
       " 0.006173407867489513,\n",
       " 0.0019910991293945633,\n",
       " 0.00390882447846516,\n",
       " 0.0062434465818126785,\n",
       " -0.01787653490955685,\n",
       " 0.04090257936240722,\n",
       " -0.021691975211693235,\n",
       " -0.03772749222152045,\n",
       " -0.008678123924813107,\n",
       " -0.011466329439768896,\n",
       " -0.019464078480000233,\n",
       " 0.018009943137524114,\n",
       " -0.002394655386837645,\n",
       " 0.00460254102403394,\n",
       " -0.0032017674360625414,\n",
       " 0.016942686627011365,\n",
       " -0.00492271760465875,\n",
       " -0.017943238092217945,\n",
       " 0.012633640724273289,\n",
       " -0.036126608387073864,\n",
       " 0.0008854888360036738,\n",
       " 0.016902663972356676,\n",
       " 0.01135960453377565,\n",
       " 0.03772749222152045,\n",
       " -0.0043690784877363,\n",
       " 0.0014324574134709116,\n",
       " 0.002981646095090643,\n",
       " -0.005036113573976135,\n",
       " -0.0025514083783186154,\n",
       " -0.035299485941844164,\n",
       " 0.0015350140690397413,\n",
       " 0.01688932370835347,\n",
       " 0.0189437914200696,\n",
       " 0.03151072803035926,\n",
       " 0.028495731508091236,\n",
       " -0.008124485273551927,\n",
       " 0.014608064058002577,\n",
       " 0.017703105889579972,\n",
       " 0.02139848009039737,\n",
       " 0.009445214250705854,\n",
       " 0.018810383192102334,\n",
       " 0.0029066045489356423,\n",
       " -0.015461868893883762,\n",
       " -0.004479139391052884,\n",
       " 0.016102222055133383,\n",
       " -0.008778179630127288,\n",
       " -0.0010739261768530836,\n",
       " -0.014314568936706714,\n",
       " 0.0077576159062708264,\n",
       " 0.024680291205954847,\n",
       " -0.007010536907705424,\n",
       " -0.02223894279963028,\n",
       " -0.007163954600354959,\n",
       " -0.02119836867976901,\n",
       " -0.014781493077979456,\n",
       " 0.0043023753050752045,\n",
       " 0.00795772638557665,\n",
       " 0.0049260526706595515,\n",
       " -0.02218557988097239,\n",
       " -0.0007404087501484835,\n",
       " 0.01953078166266133,\n",
       " 0.009932149719305939,\n",
       " -0.0068070913623988,\n",
       " 0.017889875173560055,\n",
       " 0.043997621193984614,\n",
       " -0.0008329598002613,\n",
       " 0.01467476817198621,\n",
       " 0.0036853678386618263,\n",
       " 0.013820963336105024,\n",
       " 0.002211220703197096,\n",
       " -0.0058865828781952505,\n",
       " -0.02822891691480178,\n",
       " 0.0011614745697570397,\n",
       " 0.029402897399985237,\n",
       " 0.020517992863864704,\n",
       " 0.014127798721404095,\n",
       " 0.01222674963366004,\n",
       " -0.009672006189340623,\n",
       " 0.010485788370567121,\n",
       " 0.016622509115064018,\n",
       " -0.012173386715002147,\n",
       " -0.004018885381781743,\n",
       " -0.02982980074924837,\n",
       " -0.011586396472410419,\n",
       " -0.01522173669124579,\n",
       " -0.010919360920509316,\n",
       " -0.02512053481922118,\n",
       " -0.03004325242387993,\n",
       " 0.012847092398904853,\n",
       " 0.025240600920540167,\n",
       " 0.0026664721134670344,\n",
       " 0.020851510639815257,\n",
       " -0.021104984969101508,\n",
       " -0.032791434352858494,\n",
       " 0.018850405846757023,\n",
       " 0.009905468259976994,\n",
       " 0.02183872184101863,\n",
       " 0.00289493135227157,\n",
       " 0.023626376822090376,\n",
       " 0.018703659217431626,\n",
       " 0.006990525580378081,\n",
       " -0.006356842551130062,\n",
       " -0.00528625144027778,\n",
       " 0.0003551960833055391,\n",
       " -0.00319676483706134,\n",
       " 0.01256026740961059,\n",
       " 0.019063857521388585,\n",
       " -0.01943739608934875,\n",
       " -0.01950410113465492,\n",
       " 0.025534096041836034,\n",
       " -0.01803662366553052,\n",
       " -0.004062242636775963,\n",
       " -0.05965960149849674,\n",
       " 0.019810936519953987,\n",
       " -0.02129175425308159,\n",
       " 0.015248418150574735,\n",
       " 0.008904915863447877,\n",
       " -0.015061647935272116,\n",
       " -0.005326273629271199,\n",
       " 0.019544121926664534,\n",
       " -0.023092747635511463,\n",
       " -0.009805412554662815,\n",
       " -0.03119055238105698,\n",
       " -0.0136141827247976,\n",
       " -0.024106641227366322,\n",
       " 0.02825559744280819,\n",
       " -0.019904322093266567,\n",
       " 0.01966418802798352,\n",
       " 0.008758168302799945,\n",
       " -0.012360156930304766,\n",
       " 0.011739814165059953,\n",
       " -0.010959383575164003,\n",
       " -0.006857118749394622,\n",
       " 0.013780940681450339,\n",
       " 0.005386306679930692,\n",
       " 0.016435739831083936,\n",
       " -0.0028282279367798403,\n",
       " 0.014848197191963088,\n",
       " -0.012887114122237003,\n",
       " -0.00868479405681471,\n",
       " -0.025080512164566495,\n",
       " 0.0066636784020904,\n",
       " -0.009178400588738934,\n",
       " 0.028495731508091236,\n",
       " -0.029402897399985237,\n",
       " 0.0005244561834699278,\n",
       " -0.0007437439325646017,\n",
       " -0.0023362896363479184,\n",
       " -0.008651442465484162,\n",
       " 0.001959415071064416,\n",
       " -0.007644219936953443,\n",
       " -0.019117220440046476,\n",
       " -0.009872116668646446,\n",
       " -0.022452394474261842,\n",
       " 0.025213918529888687,\n",
       " 0.012533585950281645,\n",
       " -0.0027031590036290173,\n",
       " -0.010312359350590243,\n",
       " -0.02114500576111112,\n",
       " -0.008284573098203064,\n",
       " -0.015528572076544858,\n",
       " 0.0027098293684612537,\n",
       " 0.014261206018048821,\n",
       " -0.028575774954755533,\n",
       " -0.00020125693734742814,\n",
       " -0.0020794814052140366,\n",
       " 0.005262905512610903,\n",
       " 0.02466695094195164,\n",
       " 0.02822891691480178,\n",
       " -0.029082721750682963,\n",
       " -0.0025530761441496497,\n",
       " 0.03807435026147421,\n",
       " -0.0012156711384998142,\n",
       " 0.023239496127481933,\n",
       " -0.004435782136058664,\n",
       " 0.01268700364293118,\n",
       " -0.010805964951191932,\n",
       " -0.0023446277670111895,\n",
       " -0.002936621074265389,\n",
       " -0.012400178653636917,\n",
       " 0.00209448966787891,\n",
       " -0.011146152859144085,\n",
       " -0.0032267813623910865,\n",
       " -0.022025492987643787,\n",
       " -0.02229230571828817,\n",
       " -0.0017876535840879385,\n",
       " 0.009031652096768466,\n",
       " -0.012120023796344257,\n",
       " 0.004352402692071026,\n",
       " 0.007330713488330235,\n",
       " 0.014688108435989415,\n",
       " -0.03121723290906339,\n",
       " -0.03052351682915588,\n",
       " 0.0031200557579059386,\n",
       " -0.0017576369423428749,\n",
       " -0.008551387691492518,\n",
       " 0.021171688151762603,\n",
       " -0.014074436734068739,\n",
       " -0.016689212297725114,\n",
       " 0.0037587416189857926,\n",
       " 0.005349620022599343,\n",
       " 0.010065557015950667,\n",
       " -0.02604104283776346,\n",
       " -0.01233347547097582,\n",
       " -0.01356748993814131,\n",
       " 0.012380167326309574,\n",
       " -0.012720355234261727,\n",
       " 0.0012665325248264704,\n",
       " 0.0051828611346240675,\n",
       " -0.01692934636300816,\n",
       " -0.01700938980967246,\n",
       " 0.010912690788507713,\n",
       " 0.03305825080879302,\n",
       " -0.029216128116005154,\n",
       " -0.01619560762844596,\n",
       " 0.008844882812788384,\n",
       " 0.009351829608715813,\n",
       " -0.008344606148862557,\n",
       " -0.01915724309470116,\n",
       " -0.002886593454438933,\n",
       " 0.0025097188891554305,\n",
       " -0.002314611008850809,\n",
       " -0.013407401182167636,\n",
       " 0.00952525862869269,\n",
       " -0.021024939659792134,\n",
       " 0.025720865325816116,\n",
       " 0.004045566841110689,\n",
       " -0.019810936519953987,\n",
       " -0.0068137614944004015,\n",
       " -0.01149968196242198,\n",
       " -0.03172417970499082,\n",
       " 0.015675320568515328,\n",
       " -0.014181161640061985,\n",
       " 0.012700344838256921,\n",
       " 0.02277257198620919,\n",
       " 0.016048859136475493,\n",
       " -0.012246760960987382,\n",
       " 0.008424650526849393,\n",
       " -0.002211220703197096,\n",
       " 0.010665888453868138,\n",
       " -0.009318477086062728,\n",
       " 0.008284573098203064,\n",
       " -0.02343960567546522,\n",
       " -0.009225092444072687,\n",
       " -0.02221226227162387,\n",
       " 0.005292922037940651,\n",
       " -0.02522726065653696,\n",
       " 0.01415448018073304,\n",
       " 0.00983209401399176,\n",
       " -0.016969367155017772,\n",
       " -0.018810383192102334,\n",
       " 0.02537400728586236,\n",
       " -0.004762629314346345,\n",
       " -0.016942686627011365,\n",
       " 0.006717041320748292,\n",
       " -0.005119493017963773,\n",
       " 0.0010405744691072186,\n",
       " -0.030603560275820178,\n",
       " 0.031350641137030656,\n",
       " -0.016048859136475493,\n",
       " -0.0040222204477825445,\n",
       " 0.0042623531160817865,\n",
       " -0.003962187397123051,\n",
       " -0.019384035033335932,\n",
       " -0.01194659477636738,\n",
       " 0.020397926762545718,\n",
       " 0.023906529816737965,\n",
       " 0.013267323753521307,\n",
       " -0.04629222110833871,\n",
       " 0.020798147721157366,\n",
       " 0.033298383011430996,\n",
       " 0.007290691299336816,\n",
       " 0.02932285395332094,\n",
       " 0.0035019331550212767,\n",
       " -0.01306054314221388,\n",
       " 0.02548073312317814,\n",
       " -0.005756511113212592,\n",
       " -0.014301228672703508,\n",
       " -0.03151072803035926,\n",
       " -0.009391851332047963,\n",
       " 0.002156190251538804,\n",
       " 0.014954922097956333,\n",
       " -0.009531928760694293,\n",
       " -0.006106704684828417,\n",
       " 0.0023512978990127918,\n",
       " -0.008017759436236144,\n",
       " 0.024226707328685308,\n",
       " -0.03468581517124602,\n",
       " 0.011813188411045188,\n",
       " -0.0062267707861474045,\n",
       " 0.009725369107998514,\n",
       " -0.022652505884890203,\n",
       " 0.017076092992333557,\n",
       " -0.012640310856274891,\n",
       " -0.02780201542818372,\n",
       " 0.0022495751263594795,\n",
       " -0.011052768217154044,\n",
       " 0.016569146196406127,\n",
       " -0.016022178608469082,\n",
       " -0.009238433639398427,\n",
       " 0.013407401182167636,\n",
       " -0.015688660832518533,\n",
       " 0.0004377416443776596,\n",
       " 0.019450738215997028,\n",
       " -0.018143349502846306,\n",
       " -0.0364201053710148,\n",
       " -0.007417427998318673,\n",
       " -0.009585291679352183,\n",
       " -0.005236224053281958,\n",
       " 0.009225092444072687,\n",
       " 0.16777261392907394,\n",
       " -0.010305689218588642,\n",
       " -0.0027148319674624556,\n",
       " 0.01910388017604327,\n",
       " 0.0032684710843849055,\n",
       " -0.021225051070420494,\n",
       " 0.006700365525083018,\n",
       " 0.001117283431847303,\n",
       " -0.02601436044711198,\n",
       " -0.008538046496166778,\n",
       " -0.012586948868939535,\n",
       " -0.00034956798480621163,\n",
       " -0.033084931336799434,\n",
       " 0.0018626948974123053,\n",
       " 0.02218557988097239,\n",
       " -0.02998988950522204,\n",
       " -0.02349296859412311,\n",
       " -0.011793177083717844,\n",
       " -0.0018610273644119046,\n",
       " 0.008484683577508886,\n",
       " 0.006817096560401203,\n",
       " -0.006737052648075634,\n",
       " -0.027481837916236377,\n",
       " -0.03812771504277717,\n",
       " 0.014034414079414054,\n",
       " 0.006310150230135042,\n",
       " 0.008311254557532009,\n",
       " -0.007157284468353357,\n",
       " 0.013294005212850252,\n",
       " 0.01333402786750494,\n",
       " -0.030790331422445333,\n",
       " 0.021024939659792134,\n",
       " 0.00078835189551678,\n",
       " -0.010926031983833455,\n",
       " -0.030416790991840095,\n",
       " -0.022652505884890203,\n",
       " 0.022465734738265047,\n",
       " -0.0010380730531913008,\n",
       " -0.005859901418866305,\n",
       " 0.028522412036097643,\n",
       " 0.016569146196406127,\n",
       " 0.007971066649579856,\n",
       " 0.02464026855130016,\n",
       " 0.010605854471886108,\n",
       " 0.029803118358596885,\n",
       " 0.023186133208824043,\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with openai model we can call embed query as follows \n",
    "query_result = embeddings.embed_query(texts[0].page_content)\n",
    "query_result\n",
    "#down below is the vector representation of the text/embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone.control.pinecone.Pinecone at 0x11ab0c190>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pinecone\n",
    "\n",
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "pinecone.Pinecone(\n",
    "    api_key=os.getenv(\"PINECONE_API_KEY\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"langchain-intro\"\n",
    "# search = Pinecone.from_documents(texts, embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = Pinecone.from_documents(texts, embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is magical about autoencoder\"\n",
    "result = search.similarity_search(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='So, to sum it up, autoencoders are like magical \"thinking\" machines that can learn and understand'),\n",
       " Document(page_content=\"that doesn't exist, the autoencoder can imagine new pictures or sounds. It's like having a magical\"),\n",
       " Document(page_content='too complicated. When that happens, the autoencoder can help us make sense of it all by squishing'),\n",
       " Document(page_content=\"autoencoders. They're like special computers that work just like our brain to understand and do\")]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concept -- Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0.1, max_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"ddg-search\", \"llm-math\", \"wikipedia\"], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('duckduckgo_search',\n",
       " 'A wrapper around DuckDuckGo Search. Useful for when you need to answer questions about current events. Input should be a search query.')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools[0].name, tools[0].description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools,\n",
    "                         llm,\n",
    "                         agent=\"zero-shot-react-description\",\n",
    "                         max_iterations=3,\n",
    "                         verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "duckduckgo_search: A wrapper around DuckDuckGo Search. Useful for when you need to answer questions about current events. Input should be a search query.\n",
      "Calculator: Useful for when you need to answer questions about math.\n",
      "wikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [duckduckgo_search, Calculator, wikipedia]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "print(agent.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should search for the answer using a search engine.\n",
      "Action: duckduckgo_search\n",
      "Action Input: \"2022 world cup winner and top scorer\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mWorld Cup 2022 Qatar - Top Scorer. Six football shirts worn by Argentine megastar Lionel Messi at the 2022 World Cup in Qatar have sold for $7.8 million at auction, the auction house told AFP on Thursday.... SOCCER FIFA World Cup 2022 Top Goalscorers interactive with live data By Phil Bainbridge November 20, 2022 - December 18, 2022 - England's Harry Kane was the Golden Boot winner in the 2018 World Cup and will be hoping to repeat the feat for the Three Lions at Qatar 2022, but will face stiff competition from the world's greatest strikers. Top Scorers; FIFA World Cup Table. Search. Enter a team or competition ... Netherlands: 3: 2: 1: 0: 5: 1: 4: 7: W Won 2 - 0 against Senegal on November 21st 2022. D Drew 1 - 1 against Ecuador on ... World Cup 2022 Qatar: Latest news, Fixtures & Results, Tables, Teams, Top Scorer. The League at a glance... Country: England ... All winners; Top Scorer; All-time Topscorers; All-time appearances; All-time league table; 22.01.2024 21:52. The thunderclap who stayed true to his Sardinian 'family' ESPN Get the full FIFA World Cup stats for the 2022 season on ESPN (UK). Includes leaders in goals, assists, yellow and red cards, and longest winning streaks.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should check the Wikipedia page for the 2022 World Cup to confirm the information.\n",
      "Action: wikipedia\n",
      "Action Input: \"2022 World Cup\"\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mPage: 2022 FIFA World Cup\n",
      "Summary: The 2022 FIFA World Cup was the 22nd FIFA World Cup, the world championship for national football teams organized by FIFA. It took place in Qatar from 20 November to 18 December 2022, after the country was awarded the hosting rights in 2010. It was the first World Cup to be held in the Arab world and Muslim world, and the second held entirely in Asia after the 2002 tournament in South Korea and Japan.This tournament was the last with 32 participating teams, with the number of teams being increased to 48 for the 2026 edition. To avoid the extremes of Qatar's hot climate, the event was held in November and December instead of during the traditional months of May, June, or July. It was held over a reduced time frame of 29 days with 64 matches played in eight venues across five cities. Qatar entered the eventtheir first World Cupautomatically as the host's national team, alongside 31 teams determined by the qualification process.\n",
      "Argentina were crowned the champions after winning the final against the title holder France 42 on penalties following a 33 draw after extra time. It was Argentina's third title and their first since 1986, as well as being the first nation from outside of Europe to win the tournament since 2002. French player Kylian Mbapp became the first player to score a hat-trick in a World Cup final since Geoff Hurst in the 1966 final and won the Golden Boot as he scored the most goals (eight) during the tournament. Argentine captain Lionel Messi was voted the tournament's best player, winning the Golden Ball. The tournament has been considered exceptionally poetic as the capstone of his career, for some commentators fulfilling a previously unmet criterion to be regarded as the greatest player of all time. Teammates Emiliano Martnez and Enzo Fernndez won the Golden Glove, awarded to the tournament's best goalkeeper; and the Young Player Award, awarded to the tournament's best young player, respectively. With 172 goals, the tournament set a record for the highest number of goals scored in the 32-team format, with every participating team scoring at least one goal.\n",
      "The choice to host the World Cup in Qatar attracted significant criticism, with concerns raised over the country's treatment of migrant workers, women, and members of the LGBT community, as well as Qatar's climate, lack of a strong football culture, scheduling changes, and allegations of bribery for hosting rights and wider FIFA corruption.\n",
      "\n",
      "Page: 2022 FIFA World Cup qualification\n",
      "Summary: The 2022 FIFA World Cup qualification was the qualifying process which decided the 31 teams that would join hosts Qatar, who received an automatic spot, at the 2022 FIFA World Cup.\n",
      "Parallel tournaments were organised by FIFA's six confederations. Qualification began on 6 June 2019 with several matches of the AFC zone, the first being between Mongolia and Brunei, and ended on 14 June 2022 with an inter-confederation play-off between Costa Rica and New Zealand. Mongolian player Norjmoogiin Tsedenbal netted the first goal, while the last one was scored by Joel Campbell of Costa Rica. In contrast to previous editions, there was no general preliminary draw, with confederations carrying out separate draws due to their differing timelines. The qualification process suffered numerous postponements from March 2020 onwards due to the COVID-19 pandemic.\n",
      "\n",
      "Page: 2022 Under-19 Men's Cricket World Cup\n",
      "Summary: The 2022 ICC Under-19 Men's Cricket World Cup was an international limited-overs cricket tournament that was held in the West Indies in January and February 2022 with sixteen teams taking part. It was the fourteenth edition of the Under-19 Men's Cricket World Cup, and the first that was held in the West Indies. Bangladesh were the defending champions.In March 2021, Cricket West Indies confirmed that the format would be the same as previous editions, with teams competing to progress to the Plate and Super League phases of the tournament. In N\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Argentina won the 2022 World Cup and Kylian Mbapp was the top scorer with 8 goals.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Argentina won the 2022 World Cup and Kylian Mbapp was the top scorer with 8 goals.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "which team won the 2022 world cup and who was the top scorer?\n",
    "\"\"\"\n",
    "\n",
    "agent.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
